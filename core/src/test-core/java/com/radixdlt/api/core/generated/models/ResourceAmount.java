/*
 * Babylon Core API
 * No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)
 *
 * The version of the OpenAPI document: 0.1.0
 * 
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */


package com.radixdlt.api.core.generated.models;

import java.util.Objects;
import java.util.Arrays;
import java.util.Map;
import java.util.HashMap;
import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.annotation.JsonCreator;
import com.fasterxml.jackson.annotation.JsonSubTypes;
import com.fasterxml.jackson.annotation.JsonTypeInfo;
import com.fasterxml.jackson.annotation.JsonTypeName;
import com.fasterxml.jackson.annotation.JsonValue;
import com.radixdlt.api.core.generated.models.FungibleResourceAmount;
import com.radixdlt.api.core.generated.models.NonFungibleId;
import com.radixdlt.api.core.generated.models.NonFungibleResourceAmount;
import com.radixdlt.api.core.generated.models.ResourceType;
import io.swagger.annotations.ApiModel;
import io.swagger.annotations.ApiModelProperty;
import java.util.ArrayList;
import java.util.List;
import com.fasterxml.jackson.annotation.JsonPropertyOrder;

import com.fasterxml.jackson.core.type.TypeReference;

import java.io.IOException;
import java.util.logging.Level;
import java.util.logging.Logger;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashSet;

import com.fasterxml.jackson.core.JsonGenerator;
import com.fasterxml.jackson.core.JsonParser;
import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.core.JsonToken;
import com.fasterxml.jackson.databind.DeserializationContext;
import com.fasterxml.jackson.databind.JsonMappingException;
import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.MapperFeature;
import com.fasterxml.jackson.databind.SerializerProvider;
import com.fasterxml.jackson.databind.annotation.JsonDeserialize;
import com.fasterxml.jackson.databind.annotation.JsonSerialize;
import com.fasterxml.jackson.databind.deser.std.StdDeserializer;
import com.fasterxml.jackson.databind.ser.std.StdSerializer;
import com.radixdlt.api.core.generated.client.JSON;

@javax.annotation.processing.Generated(value = "org.openapitools.codegen.languages.JavaClientCodegen")
@JsonDeserialize(using = ResourceAmount.ResourceAmountDeserializer.class)
@JsonSerialize(using = ResourceAmount.ResourceAmountSerializer.class)
public class ResourceAmount extends AbstractOpenApiSchema {
    private static final Logger log = Logger.getLogger(ResourceAmount.class.getName());

    public static class ResourceAmountSerializer extends StdSerializer<ResourceAmount> {
        public ResourceAmountSerializer(Class<ResourceAmount> t) {
            super(t);
        }

        public ResourceAmountSerializer() {
            this(null);
        }

        @Override
        public void serialize(ResourceAmount value, JsonGenerator jgen, SerializerProvider provider) throws IOException, JsonProcessingException {
            jgen.writeObject(value.getActualInstance());
        }
    }

    public static class ResourceAmountDeserializer extends StdDeserializer<ResourceAmount> {
        public ResourceAmountDeserializer() {
            this(ResourceAmount.class);
        }

        public ResourceAmountDeserializer(Class<?> vc) {
            super(vc);
        }

        @Override
        public ResourceAmount deserialize(JsonParser jp, DeserializationContext ctxt) throws IOException, JsonProcessingException {
            JsonNode tree = jp.readValueAsTree();
            Object deserialized = null;
            ResourceAmount newResourceAmount = new ResourceAmount();
            Map<String,Object> result2 = tree.traverse(jp.getCodec()).readValueAs(new TypeReference<Map<String, Object>>() {});
            String discriminatorValue = (String)result2.get("resource_type");
            switch (discriminatorValue) {
                case "Fungible":
                    deserialized = tree.traverse(jp.getCodec()).readValueAs(FungibleResourceAmount.class);
                    newResourceAmount.setActualInstance(deserialized);
                    return newResourceAmount;
                case "FungibleResourceAmount":
                    deserialized = tree.traverse(jp.getCodec()).readValueAs(FungibleResourceAmount.class);
                    newResourceAmount.setActualInstance(deserialized);
                    return newResourceAmount;
                case "NonFungible":
                    deserialized = tree.traverse(jp.getCodec()).readValueAs(NonFungibleResourceAmount.class);
                    newResourceAmount.setActualInstance(deserialized);
                    return newResourceAmount;
                case "NonFungibleResourceAmount":
                    deserialized = tree.traverse(jp.getCodec()).readValueAs(NonFungibleResourceAmount.class);
                    newResourceAmount.setActualInstance(deserialized);
                    return newResourceAmount;
                default:
                    log.log(Level.WARNING, String.format("Failed to lookup discriminator value `%s` for ResourceAmount. Possible values: Fungible FungibleResourceAmount NonFungible NonFungibleResourceAmount", discriminatorValue));
            }

            boolean typeCoercion = ctxt.isEnabled(MapperFeature.ALLOW_COERCION_OF_SCALARS);
            int match = 0;
            JsonToken token = tree.traverse(jp.getCodec()).nextToken();
            // deserialize FungibleResourceAmount
            try {
                boolean attemptParsing = true;
                // ensure that we respect type coercion as set on the client ObjectMapper
                if (FungibleResourceAmount.class.equals(Integer.class) || FungibleResourceAmount.class.equals(Long.class) || FungibleResourceAmount.class.equals(Float.class) || FungibleResourceAmount.class.equals(Double.class) || FungibleResourceAmount.class.equals(Boolean.class) || FungibleResourceAmount.class.equals(String.class)) {
                    attemptParsing = typeCoercion;
                    if (!attemptParsing) {
                        attemptParsing |= ((FungibleResourceAmount.class.equals(Integer.class) || FungibleResourceAmount.class.equals(Long.class)) && token == JsonToken.VALUE_NUMBER_INT);
                        attemptParsing |= ((FungibleResourceAmount.class.equals(Float.class) || FungibleResourceAmount.class.equals(Double.class)) && token == JsonToken.VALUE_NUMBER_FLOAT);
                        attemptParsing |= (FungibleResourceAmount.class.equals(Boolean.class) && (token == JsonToken.VALUE_FALSE || token == JsonToken.VALUE_TRUE));
                        attemptParsing |= (FungibleResourceAmount.class.equals(String.class) && token == JsonToken.VALUE_STRING);
                    }
                }
                if (attemptParsing) {
                    deserialized = tree.traverse(jp.getCodec()).readValueAs(FungibleResourceAmount.class);
                    // TODO: there is no validation against JSON schema constraints
                    // (min, max, enum, pattern...), this does not perform a strict JSON
                    // validation, which means the 'match' count may be higher than it should be.
                    match++;
                    log.log(Level.FINER, "Input data matches schema 'FungibleResourceAmount'");
                }
            } catch (Exception e) {
                // deserialization failed, continue
                log.log(Level.FINER, "Input data does not match schema 'FungibleResourceAmount'", e);
            }

            // deserialize NonFungibleResourceAmount
            try {
                boolean attemptParsing = true;
                // ensure that we respect type coercion as set on the client ObjectMapper
                if (NonFungibleResourceAmount.class.equals(Integer.class) || NonFungibleResourceAmount.class.equals(Long.class) || NonFungibleResourceAmount.class.equals(Float.class) || NonFungibleResourceAmount.class.equals(Double.class) || NonFungibleResourceAmount.class.equals(Boolean.class) || NonFungibleResourceAmount.class.equals(String.class)) {
                    attemptParsing = typeCoercion;
                    if (!attemptParsing) {
                        attemptParsing |= ((NonFungibleResourceAmount.class.equals(Integer.class) || NonFungibleResourceAmount.class.equals(Long.class)) && token == JsonToken.VALUE_NUMBER_INT);
                        attemptParsing |= ((NonFungibleResourceAmount.class.equals(Float.class) || NonFungibleResourceAmount.class.equals(Double.class)) && token == JsonToken.VALUE_NUMBER_FLOAT);
                        attemptParsing |= (NonFungibleResourceAmount.class.equals(Boolean.class) && (token == JsonToken.VALUE_FALSE || token == JsonToken.VALUE_TRUE));
                        attemptParsing |= (NonFungibleResourceAmount.class.equals(String.class) && token == JsonToken.VALUE_STRING);
                    }
                }
                if (attemptParsing) {
                    deserialized = tree.traverse(jp.getCodec()).readValueAs(NonFungibleResourceAmount.class);
                    // TODO: there is no validation against JSON schema constraints
                    // (min, max, enum, pattern...), this does not perform a strict JSON
                    // validation, which means the 'match' count may be higher than it should be.
                    match++;
                    log.log(Level.FINER, "Input data matches schema 'NonFungibleResourceAmount'");
                }
            } catch (Exception e) {
                // deserialization failed, continue
                log.log(Level.FINER, "Input data does not match schema 'NonFungibleResourceAmount'", e);
            }

            if (match == 1) {
                ResourceAmount ret = new ResourceAmount();
                ret.setActualInstance(deserialized);
                return ret;
            }
            throw new IOException(String.format("Failed deserialization for ResourceAmount: %d classes match result, expected 1", match));
        }

        /**
         * Handle deserialization of the 'null' value.
         */
        @Override
        public ResourceAmount getNullValue(DeserializationContext ctxt) throws JsonMappingException {
            throw new JsonMappingException(ctxt.getParser(), "ResourceAmount cannot be null");
        }
    }

    // store a list of schema names defined in oneOf
    public static final Map<String, Class<?>> schemas = new HashMap<>();

    public ResourceAmount() {
        super("oneOf", Boolean.FALSE);
    }

    public ResourceAmount(FungibleResourceAmount o) {
        super("oneOf", Boolean.FALSE);
        setActualInstance(o);
    }

    public ResourceAmount(NonFungibleResourceAmount o) {
        super("oneOf", Boolean.FALSE);
        setActualInstance(o);
    }

    static {
        schemas.put("FungibleResourceAmount", FungibleResourceAmount.class);
        schemas.put("NonFungibleResourceAmount", NonFungibleResourceAmount.class);
        JSON.registerDescendants(ResourceAmount.class, Collections.unmodifiableMap(schemas));
        // Initialize and register the discriminator mappings.
        Map<String, Class<?>> mappings = new HashMap<String, Class<?>>();
        mappings.put("Fungible", FungibleResourceAmount.class);
        mappings.put("FungibleResourceAmount", FungibleResourceAmount.class);
        mappings.put("NonFungible", NonFungibleResourceAmount.class);
        mappings.put("NonFungibleResourceAmount", NonFungibleResourceAmount.class);
        mappings.put("ResourceAmount", ResourceAmount.class);
        JSON.registerDiscriminator(ResourceAmount.class, "resource_type", mappings);
    }

    @Override
    public Map<String, Class<?>> getSchemas() {
        return ResourceAmount.schemas;
    }

    /**
     * Set the instance that matches the oneOf child schema, check
     * the instance parameter is valid against the oneOf child schemas:
     * FungibleResourceAmount, NonFungibleResourceAmount
     *
     * It could be an instance of the 'oneOf' schemas.
     * The oneOf child schemas may themselves be a composed schema (allOf, anyOf, oneOf).
     */
    @Override
    public void setActualInstance(Object instance) {
        if (JSON.isInstanceOf(FungibleResourceAmount.class, instance, new HashSet<Class<?>>())) {
            super.setActualInstance(instance);
            return;
        }

        if (JSON.isInstanceOf(NonFungibleResourceAmount.class, instance, new HashSet<Class<?>>())) {
            super.setActualInstance(instance);
            return;
        }

        throw new RuntimeException("Invalid instance type. Must be FungibleResourceAmount, NonFungibleResourceAmount");
    }

    /**
     * Get the actual instance, which can be the following:
     * FungibleResourceAmount, NonFungibleResourceAmount
     *
     * @return The actual instance (FungibleResourceAmount, NonFungibleResourceAmount)
     */
    @Override
    public Object getActualInstance() {
        return super.getActualInstance();
    }

    /**
     * Get the actual instance of `FungibleResourceAmount`. If the actual instance is not `FungibleResourceAmount`,
     * the ClassCastException will be thrown.
     *
     * @return The actual instance of `FungibleResourceAmount`
     * @throws ClassCastException if the instance is not `FungibleResourceAmount`
     */
    public FungibleResourceAmount getFungibleResourceAmount() throws ClassCastException {
        return (FungibleResourceAmount)super.getActualInstance();
    }

    /**
     * Get the actual instance of `NonFungibleResourceAmount`. If the actual instance is not `NonFungibleResourceAmount`,
     * the ClassCastException will be thrown.
     *
     * @return The actual instance of `NonFungibleResourceAmount`
     * @throws ClassCastException if the instance is not `NonFungibleResourceAmount`
     */
    public NonFungibleResourceAmount getNonFungibleResourceAmount() throws ClassCastException {
        return (NonFungibleResourceAmount)super.getActualInstance();
    }

}

